{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e12584",
   "metadata": {},
   "source": [
    "## Vanishing/Exploding gradients problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706acda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dense name=dense, built=False>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75121e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dense name=dense_1, built=False>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(\n",
    "    scale=2, mode=\"fan_avg\", distribution=\"uniform\"\n",
    ")\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03aefbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "leaky_relu = keras.layers.LeakyReLU(alpha=0.2)\n",
    "layer = keras.layers.Dense(10, activation=leaky_relu, kernel_initializer=\"he_normal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b348f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89edd304",
   "metadata": {},
   "source": [
    "## batch normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eac6e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe77f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │         \u001b[38;5;34m3,136\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │         \u001b[38;5;34m1,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │           \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">271,346</span> (1.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m271,346\u001b[0m (1.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,978</span> (1.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m268,978\u001b[0m (1.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> (9.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,368\u001b[0m (9.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78dbb311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gamma', True),\n",
       " ('beta', True),\n",
       " ('moving_mean', False),\n",
       " ('moving_variance', False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9719872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Activation(\"elu\"),\n",
    "        keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "        keras.layers.Activation(\"elu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf0d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a2b21",
   "metadata": {},
   "source": [
    "## transfer learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df3277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1db2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = (\n",
    "    keras.datasets.fashion_mnist.load_data()\n",
    ")\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18b3724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6)  # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2  # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(\n",
    "        np.float32\n",
    "    )  # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A), (X[y_5_or_6], y_B))\n",
    "\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b044345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43986, 28, 28)\n",
      "(200, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_A.shape)\n",
    "print(X_train_B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4beaeccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3c31294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e1b10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1733143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.5598 - val_accuracy: 0.8739 - val_loss: 0.3749\n",
      "Epoch 2/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.3438 - val_accuracy: 0.8852 - val_loss: 0.3265\n",
      "Epoch 3/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.3107 - val_accuracy: 0.8931 - val_loss: 0.3032\n",
      "Epoch 4/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.2926 - val_accuracy: 0.8971 - val_loss: 0.2896\n",
      "Epoch 5/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2802 - val_accuracy: 0.8994 - val_loss: 0.2804\n",
      "Epoch 6/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.2709 - val_accuracy: 0.9023 - val_loss: 0.2733\n",
      "Epoch 7/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2634 - val_accuracy: 0.9058 - val_loss: 0.2679\n",
      "Epoch 8/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2573 - val_accuracy: 0.9081 - val_loss: 0.2637\n",
      "Epoch 9/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2520 - val_accuracy: 0.9106 - val_loss: 0.2604\n",
      "Epoch 10/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2474 - val_accuracy: 0.9111 - val_loss: 0.2571\n",
      "Epoch 11/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2433 - val_accuracy: 0.9126 - val_loss: 0.2546\n",
      "Epoch 12/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2396 - val_accuracy: 0.9138 - val_loss: 0.2525\n",
      "Epoch 13/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2362 - val_accuracy: 0.9136 - val_loss: 0.2502\n",
      "Epoch 14/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2330 - val_accuracy: 0.9141 - val_loss: 0.2486\n",
      "Epoch 15/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.2300 - val_accuracy: 0.9143 - val_loss: 0.2470\n",
      "Epoch 16/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.2273 - val_accuracy: 0.9163 - val_loss: 0.2458\n",
      "Epoch 17/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2246 - val_accuracy: 0.9155 - val_loss: 0.2444\n",
      "Epoch 18/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2222 - val_accuracy: 0.9160 - val_loss: 0.2429\n",
      "Epoch 19/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.2198 - val_accuracy: 0.9165 - val_loss: 0.2416\n",
      "Epoch 20/20\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.2176 - val_accuracy: 0.9163 - val_loss: 0.2404\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(\n",
    "    X_train_A, y_train_A, epochs=20, validation_data=(X_valid_A, y_valid_A)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c4ac4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbd68900",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.keras\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2081e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3cf5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0670868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.5050 - loss: 1.0644 - val_accuracy: 0.6663 - val_loss: 0.7899\n",
      "Epoch 2/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7500 - loss: 0.6270 - val_accuracy: 0.7789 - val_loss: 0.4981\n",
      "Epoch 3/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8150 - loss: 0.3955 - val_accuracy: 0.8540 - val_loss: 0.3357\n",
      "Epoch 4/4\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8850 - loss: 0.2679 - val_accuracy: 0.8996 - val_loss: 0.2425\n",
      "Epoch 1/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9200 - loss: 0.2126 - val_accuracy: 0.9047 - val_loss: 0.2322\n",
      "Epoch 2/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9350 - loss: 0.2031 - val_accuracy: 0.9189 - val_loss: 0.2229\n",
      "Epoch 3/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9450 - loss: 0.1946 - val_accuracy: 0.9290 - val_loss: 0.2146\n",
      "Epoch 4/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9450 - loss: 0.1869 - val_accuracy: 0.9341 - val_loss: 0.2071\n",
      "Epoch 5/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9500 - loss: 0.1800 - val_accuracy: 0.9432 - val_loss: 0.2003\n",
      "Epoch 6/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9550 - loss: 0.1737 - val_accuracy: 0.9473 - val_loss: 0.1940\n",
      "Epoch 7/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9550 - loss: 0.1678 - val_accuracy: 0.9523 - val_loss: 0.1882\n",
      "Epoch 8/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9600 - loss: 0.1625 - val_accuracy: 0.9564 - val_loss: 0.1829\n",
      "Epoch 9/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9700 - loss: 0.1576 - val_accuracy: 0.9584 - val_loss: 0.1781\n",
      "Epoch 10/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9800 - loss: 0.1531 - val_accuracy: 0.9584 - val_loss: 0.1736\n",
      "Epoch 11/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9800 - loss: 0.1490 - val_accuracy: 0.9615 - val_loss: 0.1695\n",
      "Epoch 12/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9800 - loss: 0.1451 - val_accuracy: 0.9655 - val_loss: 0.1656\n",
      "Epoch 13/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9850 - loss: 0.1414 - val_accuracy: 0.9675 - val_loss: 0.1620\n",
      "Epoch 14/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9850 - loss: 0.1380 - val_accuracy: 0.9706 - val_loss: 0.1586\n",
      "Epoch 15/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9900 - loss: 0.1348 - val_accuracy: 0.9706 - val_loss: 0.1554\n",
      "Epoch 16/16\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9900 - loss: 0.1318 - val_accuracy: 0.9726 - val_loss: 0.1523\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(\n",
    "    X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B)\n",
    ")\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n",
    "model_B_on_A.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model_B_on_A.fit(\n",
    "    X_train_B, y_train_B, epochs=16, validation_data=(X_valid_B, y_valid_B)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cfb6dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.1435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14353129267692566, 0.9754999876022339]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2da2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "152518cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f010476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c408d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79e2b517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6384c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1 ** (epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1d5f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 ** (epoch / s)\n",
    "\n",
    "    return exponential_decay_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c1e2647",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12f3bea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs defined at (most recent call last):\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n\n  File \"C:\\Users\\sisyphus\\AppData\\Local\\Temp\\ipykernel_18880\\1917524324.py\", line 3, in <module>\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 399, in fit\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 241, in function\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 154, in multi_step_on_iterator\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 125, in wrapper\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 134, in one_step_on_data\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 81, in train_step\n\nIncompatible shapes: [32] vs. [32,10]\n\t [[{{node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs}}]] [Op:__inference_multi_step_on_iterator_128658]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[0;32m      2\u001b[0m lr_schedule \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mLearningRateScheduler(exponential_decay_fn)\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs defined at (most recent call last):\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n\n  File \"C:\\Users\\sisyphus\\AppData\\Local\\Temp\\ipykernel_18880\\1917524324.py\", line 3, in <module>\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 399, in fit\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 241, in function\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 154, in multi_step_on_iterator\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 125, in wrapper\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 134, in one_step_on_data\n\n  File \"d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 81, in train_step\n\nIncompatible shapes: [32] vs. [32,10]\n\t [[{{node gradient_tape/compile_loss/mse/sub/BroadcastGradientArgs}}]] [Op:__inference_multi_step_on_iterator_128658]"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=[lr_schedule],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b66a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, learning_rate):\n",
    "    return learning_rate * 0.1 ** (1 / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2f5c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "892af0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8f2adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 20 * len(X_train)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.01)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3b888",
   "metadata": {},
   "source": [
    "## avoiding overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babad378",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(\n",
    "    100,\n",
    "    activation=\"elu\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    kernel_regularizer=keras.regularizers.l2(0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b57e774e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "RegularizedDense = partial(\n",
    "    keras.layers.Dense,\n",
    "    activation=\"elu\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    kernel_regularizer=keras.regularizers.l2(0.01),\n",
    ")\n",
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        RegularizedDense(300),\n",
    "        RegularizedDense(100),\n",
    "        RegularizedDense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42aeccf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\anaconda\\envs\\AI-related\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dropout(rate=0.2),\n",
    "        keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(rate=0.2),\n",
    "        keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(rate=0.2),\n",
    "        keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90099bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806ee2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True) for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f54e1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.17, 0.  , 0.22, 0.01, 0.05, 0.06, 0.38, 0.03, 0.01, 0.07]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0615c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.03, 0.  , 0.2 , 0.  , 0.07, 0.01, 0.66, 0.02, 0.  , 0.  ]],\n",
       "\n",
       "       [[0.23, 0.  , 0.02, 0.02, 0.  , 0.02, 0.04, 0.06, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.82, 0.  , 0.02, 0.03, 0.  , 0.04, 0.01, 0.03, 0.02, 0.02]],\n",
       "\n",
       "       [[0.14, 0.  , 0.26, 0.01, 0.14, 0.04, 0.25, 0.01, 0.  , 0.15]],\n",
       "\n",
       "       [[0.5 , 0.  , 0.05, 0.01, 0.01, 0.01, 0.4 , 0.01, 0.  , 0.01]],\n",
       "\n",
       "       [[0.35, 0.  , 0.15, 0.01, 0.02, 0.18, 0.2 , 0.01, 0.01, 0.06]],\n",
       "\n",
       "       [[0.17, 0.  , 0.37, 0.  , 0.06, 0.05, 0.33, 0.01, 0.01, 0.01]],\n",
       "\n",
       "       [[0.27, 0.  , 0.07, 0.  , 0.01, 0.  , 0.65, 0.  , 0.  , 0.  ]],\n",
       "\n",
       "       [[0.52, 0.01, 0.11, 0.  , 0.07, 0.  , 0.11, 0.08, 0.05, 0.04]],\n",
       "\n",
       "       [[0.03, 0.  , 0.69, 0.03, 0.02, 0.05, 0.08, 0.01, 0.01, 0.08]],\n",
       "\n",
       "       [[0.01, 0.  , 0.3 , 0.01, 0.05, 0.02, 0.59, 0.  , 0.  , 0.01]],\n",
       "\n",
       "       [[0.29, 0.  , 0.01, 0.  , 0.01, 0.01, 0.63, 0.04, 0.  , 0.  ]],\n",
       "\n",
       "       [[0.09, 0.  , 0.05, 0.  , 0.11, 0.07, 0.64, 0.  , 0.  , 0.03]],\n",
       "\n",
       "       [[0.43, 0.04, 0.07, 0.  , 0.05, 0.16, 0.18, 0.02, 0.02, 0.02]],\n",
       "\n",
       "       [[0.11, 0.  , 0.07, 0.16, 0.  , 0.03, 0.23, 0.26, 0.  , 0.14]],\n",
       "\n",
       "       [[0.44, 0.01, 0.05, 0.  , 0.09, 0.  , 0.39, 0.02, 0.  , 0.  ]],\n",
       "\n",
       "       [[0.02, 0.  , 0.7 , 0.  , 0.06, 0.03, 0.08, 0.07, 0.01, 0.04]],\n",
       "\n",
       "       [[0.12, 0.  , 0.72, 0.01, 0.02, 0.01, 0.09, 0.01, 0.  , 0.02]],\n",
       "\n",
       "       [[0.43, 0.  , 0.11, 0.01, 0.19, 0.08, 0.13, 0.  , 0.  , 0.04]],\n",
       "\n",
       "       [[0.11, 0.  , 0.02, 0.02, 0.03, 0.16, 0.2 , 0.03, 0.01, 0.43]],\n",
       "\n",
       "       [[0.06, 0.  , 0.37, 0.01, 0.01, 0.03, 0.12, 0.03, 0.  , 0.35]],\n",
       "\n",
       "       [[0.39, 0.  , 0.39, 0.03, 0.04, 0.  , 0.03, 0.02, 0.04, 0.05]],\n",
       "\n",
       "       [[0.57, 0.  , 0.03, 0.01, 0.06, 0.06, 0.19, 0.01, 0.01, 0.05]],\n",
       "\n",
       "       [[0.22, 0.01, 0.1 , 0.01, 0.02, 0.25, 0.21, 0.06, 0.05, 0.06]],\n",
       "\n",
       "       [[0.23, 0.  , 0.03, 0.  , 0.08, 0.08, 0.37, 0.05, 0.  , 0.15]],\n",
       "\n",
       "       [[0.04, 0.  , 0.11, 0.  , 0.03, 0.01, 0.77, 0.02, 0.  , 0.02]],\n",
       "\n",
       "       [[0.25, 0.  , 0.06, 0.  , 0.  , 0.06, 0.58, 0.01, 0.  , 0.03]],\n",
       "\n",
       "       [[0.09, 0.  , 0.02, 0.01, 0.18, 0.09, 0.47, 0.04, 0.  , 0.11]],\n",
       "\n",
       "       [[0.05, 0.  , 0.01, 0.  , 0.22, 0.24, 0.38, 0.01, 0.02, 0.07]],\n",
       "\n",
       "       [[0.81, 0.  , 0.03, 0.01, 0.02, 0.01, 0.03, 0.07, 0.  , 0.01]],\n",
       "\n",
       "       [[0.04, 0.  , 0.46, 0.01, 0.03, 0.03, 0.31, 0.06, 0.02, 0.04]],\n",
       "\n",
       "       [[0.08, 0.  , 0.31, 0.02, 0.01, 0.06, 0.51, 0.  , 0.  , 0.01]],\n",
       "\n",
       "       [[0.12, 0.01, 0.14, 0.02, 0.02, 0.19, 0.31, 0.01, 0.04, 0.16]],\n",
       "\n",
       "       [[0.12, 0.  , 0.22, 0.  , 0.01, 0.01, 0.61, 0.01, 0.  , 0.02]],\n",
       "\n",
       "       [[0.08, 0.01, 0.41, 0.04, 0.01, 0.09, 0.13, 0.02, 0.04, 0.17]],\n",
       "\n",
       "       [[0.01, 0.  , 0.28, 0.  , 0.1 , 0.01, 0.54, 0.01, 0.  , 0.06]],\n",
       "\n",
       "       [[0.01, 0.  , 0.15, 0.  , 0.05, 0.25, 0.45, 0.01, 0.  , 0.08]],\n",
       "\n",
       "       [[0.14, 0.  , 0.6 , 0.  , 0.1 , 0.  , 0.09, 0.02, 0.  , 0.04]],\n",
       "\n",
       "       [[0.08, 0.  , 0.04, 0.04, 0.02, 0.06, 0.11, 0.21, 0.08, 0.36]],\n",
       "\n",
       "       [[0.4 , 0.  , 0.1 , 0.01, 0.  , 0.01, 0.41, 0.01, 0.  , 0.06]],\n",
       "\n",
       "       [[0.21, 0.  , 0.22, 0.  , 0.07, 0.01, 0.4 , 0.01, 0.07, 0.02]],\n",
       "\n",
       "       [[0.17, 0.  , 0.3 , 0.03, 0.01, 0.18, 0.2 , 0.03, 0.01, 0.08]],\n",
       "\n",
       "       [[0.24, 0.02, 0.47, 0.02, 0.07, 0.07, 0.03, 0.05, 0.01, 0.02]],\n",
       "\n",
       "       [[0.34, 0.  , 0.58, 0.  , 0.01, 0.01, 0.04, 0.02, 0.  , 0.  ]],\n",
       "\n",
       "       [[0.4 , 0.  , 0.01, 0.  , 0.02, 0.26, 0.25, 0.  , 0.  , 0.05]],\n",
       "\n",
       "       [[0.1 , 0.04, 0.01, 0.01, 0.21, 0.06, 0.09, 0.45, 0.01, 0.02]],\n",
       "\n",
       "       [[0.1 , 0.04, 0.07, 0.  , 0.12, 0.14, 0.47, 0.  , 0.03, 0.03]],\n",
       "\n",
       "       [[0.48, 0.  , 0.21, 0.04, 0.01, 0.02, 0.04, 0.01, 0.1 , 0.09]],\n",
       "\n",
       "       [[0.05, 0.  , 0.13, 0.  , 0.03, 0.02, 0.73, 0.02, 0.  , 0.01]],\n",
       "\n",
       "       [[0.57, 0.01, 0.04, 0.01, 0.01, 0.19, 0.06, 0.07, 0.01, 0.04]],\n",
       "\n",
       "       [[0.01, 0.  , 0.13, 0.01, 0.31, 0.02, 0.48, 0.01, 0.01, 0.02]],\n",
       "\n",
       "       [[0.04, 0.  , 0.23, 0.  , 0.5 , 0.03, 0.07, 0.03, 0.01, 0.09]],\n",
       "\n",
       "       [[0.05, 0.  , 0.55, 0.  , 0.03, 0.04, 0.27, 0.03, 0.01, 0.02]],\n",
       "\n",
       "       [[0.13, 0.01, 0.18, 0.01, 0.05, 0.01, 0.05, 0.52, 0.  , 0.02]],\n",
       "\n",
       "       [[0.32, 0.01, 0.08, 0.05, 0.02, 0.14, 0.03, 0.25, 0.01, 0.09]],\n",
       "\n",
       "       [[0.73, 0.  , 0.01, 0.01, 0.05, 0.  , 0.11, 0.04, 0.01, 0.04]],\n",
       "\n",
       "       [[0.64, 0.01, 0.01, 0.  , 0.03, 0.01, 0.24, 0.01, 0.  , 0.05]],\n",
       "\n",
       "       [[0.01, 0.  , 0.04, 0.  , 0.01, 0.01, 0.91, 0.  , 0.  , 0.02]],\n",
       "\n",
       "       [[0.  , 0.  , 0.04, 0.  , 0.04, 0.02, 0.87, 0.01, 0.01, 0.  ]],\n",
       "\n",
       "       [[0.04, 0.01, 0.36, 0.04, 0.01, 0.07, 0.18, 0.05, 0.  , 0.25]],\n",
       "\n",
       "       [[0.05, 0.  , 0.41, 0.01, 0.01, 0.02, 0.14, 0.02, 0.  , 0.34]],\n",
       "\n",
       "       [[0.26, 0.  , 0.01, 0.16, 0.05, 0.1 , 0.31, 0.03, 0.  , 0.07]],\n",
       "\n",
       "       [[0.12, 0.  , 0.02, 0.01, 0.01, 0.64, 0.17, 0.01, 0.  , 0.01]],\n",
       "\n",
       "       [[0.06, 0.  , 0.7 , 0.  , 0.  , 0.01, 0.2 , 0.01, 0.  , 0.01]],\n",
       "\n",
       "       [[0.2 , 0.  , 0.19, 0.02, 0.02, 0.01, 0.43, 0.01, 0.  , 0.12]],\n",
       "\n",
       "       [[0.1 , 0.  , 0.05, 0.  , 0.01, 0.02, 0.79, 0.01, 0.  , 0.01]],\n",
       "\n",
       "       [[0.12, 0.  , 0.3 , 0.  , 0.08, 0.  , 0.31, 0.04, 0.01, 0.14]],\n",
       "\n",
       "       [[0.57, 0.02, 0.08, 0.  , 0.02, 0.  , 0.21, 0.03, 0.02, 0.04]],\n",
       "\n",
       "       [[0.58, 0.  , 0.11, 0.  , 0.07, 0.  , 0.13, 0.01, 0.02, 0.07]],\n",
       "\n",
       "       [[0.39, 0.  , 0.05, 0.01, 0.07, 0.03, 0.34, 0.07, 0.02, 0.03]],\n",
       "\n",
       "       [[0.07, 0.  , 0.  , 0.  , 0.01, 0.01, 0.72, 0.14, 0.04, 0.01]],\n",
       "\n",
       "       [[0.05, 0.  , 0.61, 0.01, 0.07, 0.  , 0.14, 0.01, 0.03, 0.07]],\n",
       "\n",
       "       [[0.29, 0.  , 0.1 , 0.01, 0.07, 0.02, 0.06, 0.04, 0.01, 0.39]],\n",
       "\n",
       "       [[0.1 , 0.  , 0.06, 0.05, 0.02, 0.29, 0.21, 0.03, 0.01, 0.24]],\n",
       "\n",
       "       [[0.08, 0.  , 0.42, 0.  , 0.02, 0.04, 0.42, 0.01, 0.  , 0.01]],\n",
       "\n",
       "       [[0.16, 0.01, 0.02, 0.01, 0.04, 0.16, 0.11, 0.47, 0.  , 0.02]],\n",
       "\n",
       "       [[0.1 , 0.  , 0.13, 0.  , 0.09, 0.02, 0.61, 0.02, 0.01, 0.02]],\n",
       "\n",
       "       [[0.34, 0.02, 0.22, 0.03, 0.05, 0.02, 0.18, 0.04, 0.06, 0.04]],\n",
       "\n",
       "       [[0.16, 0.  , 0.01, 0.04, 0.01, 0.02, 0.68, 0.07, 0.  , 0.01]],\n",
       "\n",
       "       [[0.06, 0.  , 0.21, 0.02, 0.16, 0.05, 0.31, 0.04, 0.12, 0.01]],\n",
       "\n",
       "       [[0.07, 0.  , 0.17, 0.01, 0.05, 0.05, 0.31, 0.25, 0.  , 0.09]],\n",
       "\n",
       "       [[0.43, 0.  , 0.36, 0.01, 0.03, 0.02, 0.1 , 0.02, 0.  , 0.01]],\n",
       "\n",
       "       [[0.33, 0.01, 0.33, 0.03, 0.07, 0.05, 0.14, 0.01, 0.01, 0.02]],\n",
       "\n",
       "       [[0.49, 0.  , 0.05, 0.02, 0.01, 0.27, 0.1 , 0.03, 0.  , 0.02]],\n",
       "\n",
       "       [[0.23, 0.  , 0.09, 0.01, 0.  , 0.01, 0.32, 0.16, 0.  , 0.18]],\n",
       "\n",
       "       [[0.07, 0.  , 0.32, 0.  , 0.01, 0.02, 0.55, 0.02, 0.  , 0.01]],\n",
       "\n",
       "       [[0.59, 0.  , 0.07, 0.01, 0.05, 0.02, 0.17, 0.01, 0.01, 0.07]],\n",
       "\n",
       "       [[0.01, 0.  , 0.11, 0.01, 0.05, 0.01, 0.05, 0.04, 0.  , 0.71]],\n",
       "\n",
       "       [[0.72, 0.  , 0.02, 0.1 , 0.  , 0.01, 0.03, 0.01, 0.  , 0.12]],\n",
       "\n",
       "       [[0.26, 0.  , 0.02, 0.01, 0.11, 0.14, 0.1 , 0.01, 0.02, 0.32]],\n",
       "\n",
       "       [[0.12, 0.  , 0.06, 0.03, 0.14, 0.47, 0.07, 0.01, 0.09, 0.03]],\n",
       "\n",
       "       [[0.1 , 0.  , 0.11, 0.01, 0.08, 0.33, 0.34, 0.  , 0.01, 0.01]],\n",
       "\n",
       "       [[0.11, 0.  , 0.74, 0.  , 0.04, 0.  , 0.08, 0.01, 0.  , 0.01]],\n",
       "\n",
       "       [[0.03, 0.  , 0.14, 0.01, 0.02, 0.02, 0.76, 0.  , 0.01, 0.01]],\n",
       "\n",
       "       [[0.01, 0.  , 0.23, 0.  , 0.01, 0.09, 0.64, 0.01, 0.  , 0.  ]],\n",
       "\n",
       "       [[0.09, 0.  , 0.02, 0.02, 0.06, 0.18, 0.57, 0.  , 0.01, 0.04]],\n",
       "\n",
       "       [[0.02, 0.  , 0.66, 0.01, 0.04, 0.01, 0.02, 0.07, 0.01, 0.17]],\n",
       "\n",
       "       [[0.03, 0.  , 0.45, 0.  , 0.17, 0.04, 0.16, 0.  , 0.  , 0.14]],\n",
       "\n",
       "       [[0.12, 0.  , 0.04, 0.  , 0.03, 0.19, 0.6 , 0.  , 0.  , 0.  ]],\n",
       "\n",
       "       [[0.39, 0.  , 0.09, 0.  , 0.1 , 0.06, 0.09, 0.09, 0.14, 0.02]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a0821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22, 0.  , 0.19, 0.01, 0.06, 0.07, 0.3 , 0.05, 0.01, 0.08]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ff189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2 , 0.01, 0.2 , 0.02, 0.07, 0.1 , 0.23, 0.09, 0.03, 0.12]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43119370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.1611)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cb07a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ceffb54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dense name=dense_23, built=False>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(\n",
    "    100,\n",
    "    activation=\"elu\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    kernel_constraint=keras.constraints.max_norm(1.0),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-related",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
